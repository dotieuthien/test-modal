{"date": "20251028-044319", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "/llama_models/Qwen/Qwen2.5-VL-7B-Instruct-AWQ", "tokenizer_id": "/llama_models/Qwen/Qwen2.5-VL-7B-Instruct-AWQ", "num_prompts": 100, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": null, "duration": 36.92536778899998, "completed": 100, "total_input_tokens": 23260, "total_output_tokens": 21824, "request_throughput": 2.7081653071520626, "request_goodput": null, "output_throughput": 591.0299966328661, "total_token_throughput": 1220.9492470764358, "max_output_tokens_per_s": 1097.0, "max_concurrent_requests": 100, "mean_ttft_ms": 10459.284663379998, "median_ttft_ms": 10715.905651999989, "std_ttft_ms": 6566.078683236744, "p99_ttft_ms": 22432.771191130007, "mean_tpot_ms": 53.34318277307475, "median_tpot_ms": 40.6518140263158, "std_tpot_ms": 59.62980636854676, "p99_tpot_ms": 379.39697911333155, "mean_itl_ms": 36.35705748807769, "median_itl_ms": 27.732344500009276, "std_itl_ms": 55.86689737096493, "p99_itl_ms": 260.06818915998116}